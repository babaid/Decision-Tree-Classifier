{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2d6682-e61a-48cd-ad39-c24eec58689b",
   "metadata": {},
   "source": [
    "# Decision Tree Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc7b273-b0f9-4a1d-9f3c-90cfb1037616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/repos/Decision-Tree-Classifier`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/repos/Decision-Tree-Classifier/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/repos/Decision-Tree-Classifier/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.add([\"StatsBase\", \"DataFrames\", \"MLDatasets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe4c2fc-66d3-43d5-963b-af132ef8bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, DataFrames, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5610c80a-39af-405e-ba72-451b1e08c074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load iris dataset\n",
    "iris = Iris()\n",
    "#add class labels as numbers\n",
    "str_to_class = Dict{String, Int64}([(\"Iris-setosa\", 0) ,(\"Iris-versicolor\", 1), (\"Iris-virginica\", 2)])\n",
    "class_to_str = Dict{Int64, String}([(v, k) for (k, v) in str_to_class])\n",
    "map(i->(str_to_class[i]), iris.targets.class)\n",
    "\n",
    "#I merge here the targets into the feature DataFrame for easier filtering later on.\n",
    "iris.features.class = map(i->(str_to_class[i]), iris.targets.class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59b4b4f-82e6-45b5-afea-9ad829da098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×5 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">sepallength</th><th style = \"text-align: left;\">sepalwidth</th><th style = \"text-align: left;\">petallength</th><th style = \"text-align: left;\">petalwidth</th><th style = \"text-align: left;\">class</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">4.9</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">4.7</td><td style = \"text-align: right;\">3.2</td><td style = \"text-align: right;\">1.3</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">4.6</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">3.6</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& sepallength & sepalwidth & petallength & petalwidth & class\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & 0 \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & 0 \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & 0 \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & 0 \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m sepallength \u001b[0m\u001b[1m sepalwidth \u001b[0m\u001b[1m petallength \u001b[0m\u001b[1m petalwidth \u001b[0m\u001b[1m class \u001b[0m\n",
       "     │\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────\n",
       "   1 │         5.1         3.5          1.4         0.2      0\n",
       "   2 │         4.9         3.0          1.4         0.2      0\n",
       "   3 │         4.7         3.2          1.3         0.2      0\n",
       "   4 │         4.6         3.1          1.5         0.2      0\n",
       "   5 │         5.0         3.6          1.4         0.2      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at the dataset.\n",
    "iris.features[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9e160d-a8bb-4cef-8b53-1491291c1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Node end\n",
    "#Define Tree Nodes\n",
    "\n",
    "mutable struct ClassifierNode <: Node\n",
    "    left::Union{Node, Missing}\n",
    "    right::Union{Node, Missing}\n",
    "    split::Union{String, Missing}\n",
    "    depth::Union{Int64, Missing}\n",
    "    thresh::Union{Float64, Missing}\n",
    "    gini::Union{Float64, Missing}\n",
    "    class_count::Union{Dict{Int64, Int64}, Missing}\n",
    "end\n",
    "\n",
    "mutable struct DecisionTreeClassifier\n",
    "    root::ClassifierNode\n",
    "    impurity_measure::Function\n",
    "    max_depth::Int64\n",
    "    min_impurity_decrease::Float64\n",
    "    min_samples_leaf::Int64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b380b204-aae7-40dc-b3b4-e081df391d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierNode"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassifierNode(i::Int64) = ClassifierNode(missing, missing, missing, i, missing, missing, missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61e0d8c-1ffe-490c-a323-64a31be953ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier(impurity_measure::Function, max_depth::Int64, min_impurity_decrease::Float64, min_samples_leaf::Int64) = DecisionTreeClassifier(ClassifierNode(0),impurity_measure,\n",
    "    max_depth, min_impurity_decrease, min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56eff1a9-cfed-4057-a50e-8b0b6a3218a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts each class\n",
    "function class_distribution(data, classes)\n",
    "    d = Dict{Int64, Int64}()\n",
    "    for class in classes\n",
    "        d[class] = count(i->(i==class), data)\n",
    "    end\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea97144-4b5d-44d2-9f86-7b67d91a9d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gini_impurity (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#claculates gini impurity for a class distribution\n",
    "function gini_impurity(dist)\n",
    "    nums = [v for v in values(dist)]\n",
    "    probs = (nums./sum(nums)).^2\n",
    "    return 1-sum(probs)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5b1c2-599d-4d7c-9602-9186e703ca50",
   "metadata": {},
   "source": [
    "Now that we have set up the helper functions, we have to think about how a decision tree works.\n",
    "1. Find the best feature to split the values\n",
    "2. Perform split and add new nodes\n",
    "3. Perform this recurisvely\n",
    "\n",
    "So step-by-step this looks as follows:\n",
    "First we need to iterate through every feature and evaluate splits at different values with our impurity measure (gini). There are multiple ways to choose split values, I used quantiles of a feature. You can also make smarter choices e.g. heuristically or some other statistical stuff (feel free to try). We compare these for every feature and when we found the best, we split the dataset like that and add new nodes on the left and right sides with the appropriate values and call the train function on those nodes (with the splitted data).\n",
    "\n",
    "Next step is to implement guards when to stop. Max_depth prevents overall growth, min_samples_leaf prevents too many lone leafs (overffitting). One other important hyperparameter is min_impurity_decrease, it makes sure that the gini impurity decreases at least a minimal amount. \n",
    "\n",
    "In the end this leaves us with a nice fitted decision tree clasifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a51e779c-c2c9-481f-bb81-643cbbf33ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 5 methods)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(classifier_node::ClassifierNode, data::DataFrame, target_name::Symbol,classes::Vector{Int64}, impurity_measure::Function ,maxdepth::Int64 = 5, min_samples_leaf::Int64 = 3, min_impurity_decrease::Float64 = 0.1)\n",
    "    \n",
    "    if classifier_node.depth >= maxdepth || size(data)[1] <= min_samples_leaf\n",
    "        #turn node into leaf\n",
    "        #classifier_node = Leaf(classifier_node)\n",
    "        return\n",
    "    end\n",
    "    #initialization\n",
    "    feature_names = [name for name in names(data) if name != String(target_name)]\n",
    "    \n",
    "    best_feature = \"\"\n",
    "    best_split_val = Inf\n",
    "    #initial distribution of classes for node\n",
    "    init_dist = class_distribution(data[!, target_name], classes)\n",
    "\n",
    "    #GINIs\n",
    "    parent_gini = impurity_measure(init_dist)\n",
    "    best_gini = impurity_measure(init_dist)\n",
    "\n",
    "    \n",
    "    #set for the current node\n",
    "    classifier_node.class_count = copy(init_dist)\n",
    "    classifier_node.gini = copy(best_gini)\n",
    "    \n",
    "    for feature in feature_names\n",
    "            values = sort(data, [Symbol(feature)])\n",
    "            #calculate the initial distributio\n",
    "            splitvals = [quantile(values[!, Symbol(feature)], t) for t in 0.01:0.01:0.99]\n",
    "            for splitval in splitvals\n",
    "                prediction_mask = values[!, Symbol(feature)] .< splitval\n",
    "                subset = data[prediction_mask, :]\n",
    "                new_dist = class_distribution(subset[!, target_name], classes)\n",
    "                curr_gini = impurity_measure(new_dist)            \n",
    "                if (curr_gini <= best_gini) && (size(subset)[1] >= min_samples_leaf)\n",
    "                    #println(\"New_best_gini:\", curr_gini)\n",
    "                    best_gini = copy(curr_gini)\n",
    "                    best_split_val = copy(splitval)\n",
    "                    best_feature = feature\n",
    "                end\n",
    "            end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if best_feature != \"\"\n",
    "\n",
    "        # Update classifier_node with the best split information\n",
    "       \n",
    "                \n",
    "        # Create left child node4\n",
    "    \n",
    "        if (abs(best_gini-parent_gini) >= min_impurity_decrease)\n",
    "            \n",
    "            classifier_node.split = best_feature\n",
    "            classifier_node.thresh = best_split_val\n",
    "           \n",
    "            classifier_node.left = ClassifierNode(classifier_node.depth + 1)\n",
    "            classifier_node.left.gini = copy(best_gini)\n",
    "           \n",
    "            left_mask = data[!, best_feature] .< best_split_val\n",
    "            left_data = data[left_mask, :]\n",
    "            classifier_node.left.class_count = class_distribution(left_data[!, target_name], classes)\n",
    "            \n",
    "            train!(classifier_node.left, left_data, target_name,classes, impurity_measure, maxdepth, min_samples_leaf)\n",
    "        \n",
    "            # Create right child node\n",
    "            right_data = data[.!left_mask, :]\n",
    "            right_dist = class_distribution(right_data[!, target_name], classes)\n",
    "            \n",
    "            right_gini =  impurity_measure(right_dist)\n",
    "        \n",
    "            #println(parent_gini)\n",
    "            #println(right_gini)\n",
    "           \n",
    "            classifier_node.right = ClassifierNode(classifier_node.depth + 1)            \n",
    "            classifier_node.right.gini = copy(right_gini)\n",
    "            classifier_node.right.class_count = right_dist\n",
    "            train!(classifier_node.right, right_data, target_name,classes, impurity_measure, maxdepth, min_samples_leaf)\n",
    "            \n",
    "        else return end\n",
    "    else return end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "789a98d8-2ab4-4337-b1dd-5baa2ca85ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 5 methods)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(tree::DecisionTreeClassifier, data::DataFrame, target_name::Symbol, classes::Vector{Int64})\n",
    "    train!(tree.root, data, target_name,classes, tree.impurity_measure, tree.max_depth, tree.min_samples_leaf, tree.min_impurity_decrease)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec3e7d25-231f-45dd-88c3-c39e08b97205",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = DecisionTreeClassifier(gini_impurity, 2, 0.1, 10)\n",
    "train!(t, iris.features, :class, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7426a351-071e-4030-b97c-d2d9a5b2eedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 2 methods)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(DT::DecisionTreeClassifier, x::Union{DataFrame, DataFrameRow}, cstr)\n",
    "    curr_node = DT.root\n",
    "    while !ismissing(curr_node.thresh)\n",
    "        if x[curr_node.split] < curr_node.thresh\n",
    "            curr_node = curr_node.left\n",
    "        else\n",
    "            curr_node = curr_node.right\n",
    "        end\n",
    "    end\n",
    "    return cstr[findprob(curr_node.class_count)]\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a1b1621-e859-4da6-bb96-b517cecea094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findprob (generic function with 1 method)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findprob(d)\n",
    "    m = 0\n",
    "    mk = 0\n",
    "    for k in keys(d)\n",
    "        if d[k]>m\n",
    "            m = d[k]\n",
    "            mk = k\n",
    "        end\n",
    "    end\n",
    "    return mk\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0952465e-5587-4148-b340-68281ad174e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Iris-virginica\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(t, iris.features[140, :], class_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "48a87d28-27b8-4d68-84f6-38945bce0a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "traverse (generic function with 1 method)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a helper function to show the tree structure\n",
    "#approximately....\n",
    "function traverse(node::ClassifierNode, spacing)\n",
    "    \n",
    "    #operations on current node\n",
    "    dp = 15\n",
    "    p = repeat(\" \", spacing)\n",
    "    \n",
    "    \n",
    "    if !ismissing(node.thresh)\n",
    "        println(\"$(p)|$(node.split) < $(node.thresh)\")\n",
    "        println(\"$(p)|class distribution: $(values(node.class_count))\")\n",
    "        println(\"$(p)-----------------------------------------------\")\n",
    "    else\n",
    "        l = length(\"$(p)Predicted Class: $(  class_to_str[findprob(node.class_count)])\")\n",
    "        #p2 = repeat(\" \", spacing+12)\n",
    "        \n",
    "        println(\"$(p)Predicted Class: $(  class_to_str[findprob(node.class_count)])\")\n",
    "        println(\"$(p)|class distribution: $(values(node.class_count))\")\n",
    "    end\n",
    "    \n",
    "    if !ismissing(node.left)\n",
    "        for i in 1:5\n",
    "            np = repeat(\" \", spacing-i)\n",
    "            pp = repeat(\" \", spacing+2*i)\n",
    "            if !ismissing(node.right)\n",
    "               println(\"$(np)/$(pp)\\\\\")\n",
    "            else\n",
    "               println(\"$(np)\")\n",
    "            end\n",
    "                \n",
    "        end\n",
    "        traverse(node.left, spacing-dp )\n",
    "    end\n",
    "    if !ismissing(node.right)\n",
    "         for i in 1:5\n",
    "            np = repeat(\" \", 2*spacing+i+8)\n",
    "            println(\"$(np)\\\\\")\n",
    "        end\n",
    "        traverse(node.right, 2*spacing-dp)\n",
    "    end\n",
    "end      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "af08e2e3-7c67-4fce-aac2-ca7d44d82b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              |petalwidth < 1.0\n",
      "                              |class distribution: [50, 50, 50]\n",
      "                              -----------------------------------------------\n",
      "                             /                                \\\n",
      "                            /                                  \\\n",
      "                           /                                    \\\n",
      "                          /                                      \\\n",
      "                         /                                        \\\n",
      "               Predicted Class: Iris-setosa\n",
      "               |class distribution: [50, 0, 0]\n",
      "                                                                     \\\n",
      "                                                                      \\\n",
      "                                                                       \\\n",
      "                                                                        \\\n",
      "                                                                         \\\n",
      "                                             |petalwidth < 1.6\n",
      "                                             |class distribution: [0, 50, 50]\n",
      "                                             -----------------------------------------------\n",
      "                                            /                                               \\\n",
      "                                           /                                                 \\\n",
      "                                          /                                                   \\\n",
      "                                         /                                                     \\\n",
      "                                        /                                                       \\\n",
      "                              Predicted Class: Iris-versicolor\n",
      "                              |class distribution: [0, 3, 45]\n",
      "                                                                                                   \\\n",
      "                                                                                                    \\\n",
      "                                                                                                     \\\n",
      "                                                                                                      \\\n",
      "                                                                                                       \\\n",
      "                                                                           Predicted Class: Iris-virginica\n",
      "                                                                           |class distribution: [0, 47, 5]\n"
     ]
    }
   ],
   "source": [
    "traverse(t.root, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b560997-3f18-4595-ad2c-54d0c5dbc6cf",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We have seen a really straightforward method to implement a decision tree and more importantly how to fit it to numerical data for classification. We also tested it on the iris dataset, so we know it works alright. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd5723-5468-46c0-b52b-c3a398a26864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
